---
title: "Predicting Loan Defaults"
author: "Karolina Frieszova"
date: "03/03/2021"
output:
  html_document:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr, warn.conflicts = FALSE)
# Suppress summarise info
options(dplyr.summarise.inform = FALSE)

iris %>% 
  group_by(Species) %>% 
  summarise(
    Sepal.Length.mean = mean(Sepal.Length)
  )
```


## 1. INTRODUCTION

### 1.1 Business Understanding

LendingClub is a US peer-to-peer lending company and the world's largest peer-to-peer lending platform. LendingClub enables borrowers to create unsecured personal loans. Investors can search and browse the loan listings on the LendingClub website and select loans that they want to invest in based on the information supplied about the borrower. It is an online financial application service that directly connects individual investors and loan borrowers to establish credit relationships and complete the transaction procedures through an online platform, without the intermediaries of commercial banks. Investors make money from the interest on these loans. LendingClub makes money by charging borrowers an origination fee and investors a service fee. 

### 1.2 Business Problem

Peer_to_peer online lending platform has brought opportunities to investors, but at the same time, investors are also faced with the risk of user loan default, which is related to the sustainable and healthy development of the LendingClub's platform. Investors want to maximise their profit and minimase their risk, in other words investors want to avoid funding loans that won't be fully paid off but equally, they do not want to miss on the opportunity to lend to someone who would pay back.

### 1.3 Project Goal

The aim of this project is to develop a machine learning model on a data provided by an online loan provider called LendingClub to improve their risk assessment and understanding of who is likely to default and who they should lend to in the future.

My purpose of the project was to build a model that identifies right characteristics of the two types of borrowers and establish most favourable cut off point of accepted loan applications to maximise the business profit.

### 1.4 Data Source

Data-set used contains historical data from LendingClub. The data is openly available on their website.

### 1.5 References

Original Data Source [LendingClub website](https://www.lendingclub.com/investing/peer-to-peer)

General information about business [Wikipedia page](https://en.wikipedia.org/wiki/LendingClub)

Different loan statuses explained [LendingClub HelpPage](https://help.lendingclub.com/hc/en-us/articles/215488038-What-do-the-different-Note-statuses-mean-?fbclid=IwAR0DVRxmLkmOGPSwOz0FpWiJJBRNE2KuW0lvnbp5Mq7d9cZHy6g7dOcKMOk)

### 1.6 Method

To build the predictive model I used supervised machine learning method (making predictions from labeled data), specifically, a logistic regression algorithm as a classifier for loan status. 

Logistic regression is a statistical model that in its basic form uses a logistic function to model a binary dependent variable with two possible values, such as loan paid or loan charged-off.

## 2. DATA PREPERATION

### 2.1 Data Introdustion

The raw data from the LendingClub contains 42538 rows and 114 columns. Each observation represents one borrower and her/his information. The personal loans are between $500 to \$35000. The standard loan duration is 3 or 5 years. The period in which loans were funded is Jun 2007 to Dec 2011. 

The original data-set contains many different variables that LendingClub collects during different stages of the loan process. Many of these variables have large amounts of missing values, only a single constant value or were arbitrary to building predictive loan risk model. 
In this original data-set, there was one duplicate row that is no present after the data cleaning process. 
 
Our data-set is joined with two data-sets that added a state name to the zip code and reduced the risk grading system from 35 grades to 7.

### 2.2 Data Cleaning

#### 2.2.1 Packages used
```{r message=FALSE, echo=TRUE,cache=FALSE, results=TRUE, warning=FALSE, comment=FALSE, warning=FALSE}
library(tidyverse)
library(here)
library(janitor)
library(broom)
library(pROC)
library(modelr)
library(glmulti)
```

#### 2.2.2 Reading in data and joing tables
```{r message=FALSE, echo=TRUE,cache=FALSE, results=TRUE, warning=FALSE, comment=FALSE, warning=FALSE}
 # read in data
grade_info <- read_csv(here("raw_data/grade_info.csv"))
lcd_dictionary <- read_csv(here("raw_data/LCDataDictionary.csv")) %>% 
  clean_names()
lending_club_loans <- read_csv(here("raw_data/lending_club_loans.csv"))
state_names <- read_csv(here("raw_data/state_names_info.csv"))

# add seven loan classifiers which indicate different levels of risk and corresponding returns
lending_club_loans <- left_join(lending_club_loans, grade_info, by = "sub_grade")

# add state names
lending_club_loans <- left_join(lending_club_loans, state_names, 
                                by = c("addr_state" = "state_abb"))
```

#### 2.2.3 Initial variable reduction
In dealing with missing values, I have removed the variables with large amounts of missing values or with a constant single value throughout the column. The original data-set contains many different variables that LendingClub collects during different stages of the loan process. I have concentrated my attention at the information that the LendingClub and its investors have about an applicant during the application stage.

```{r}
# remove columns in which stored value is only NA
lending_loans <- lending_club_loans %>% 
  select(-c(total_il_high_credit_limit, mths_since_last_major_derog, num_bc_tl,
            mths_since_rcnt_il, mths_since_recent_bc, mths_since_recent_bc_dlq, 
            mths_since_recent_inq, mths_since_recent_revol_delinq, total_bc_limit,
            total_bal_ex_mort, tot_hi_cred_lim, percent_bc_gt_75, pct_tl_nvr_dlq, 
            num_tl_120dpd_2m, num_tl_30dpd, num_tl_90g_dpd_24m, num_tl_op_past_12m,
            num_sats, num_rev_tl_bal_gt_0, num_rev_accts, num_op_rev_tl, num_il_tl,
            num_bc_sats, num_actv_rev_tl, num_actv_bc_tl, num_accts_ever_120_pd,
            mort_acc, mo_sin_rcnt_tl, mo_sin_old_il_acct, mo_sin_old_rev_tl_op,
            mo_sin_rcnt_rev_tl_op, bc_util, bc_open_to_buy, avg_cur_bal, 
            acc_open_past_24mths, inq_last_12m, total_cu_tl, total_rev_hi_lim,
            inq_fi, all_util, max_bal_bc, open_rv_24m, open_rv_12m, il_util,
            total_bal_il, open_il_24m, open_il_12m, open_il_6m, open_acc_6m,
            tot_cur_bal, tot_coll_amt, verification_status_joint, dti_joint, 
            annual_inc_joint))

# remove data-sets
rm(grade_info, state_names, lending_club_loans)

# further column reduction
lending_loans <- lending_loans %>% 
  select(-c(id, member_id, url, desc, last_pymnt_d, last_pymnt_amnt, last_credit_pull_d, # unrequited
            sub_grade, addr_state, # replaced with abbreviation
            tax_liens, # only one different value
            policy_code, # only policy code = 1 or NA, no policy code = 2
            initial_list_status, # False, NA
            collections_12_mths_ex_med, chargeoff_within_12_mths, # 0, NA 
            title, # high correlation with purpose
            emp_title, next_pymnt_d, # high cardinalty and a lot missing 
            zip_code, # earliest_cr_line, # high cardinalty, not required
            funded_amnt, funded_amnt_inv, # highly correlated with loan_amount
            pymnt_plan, # only one True value - rest False
            total_pymnt_inv, # highly correlated with total_pymnt
            acc_now_delinq, # 4 rows = 1 all have loan_status = fully paid
            delinq_amnt, # 2 rows with loan_status = fully paid
            application_type, # all applications are individual
            mths_since_last_delinq, # 63.3 % missing values
            mths_since_last_record, # 91.4% missing vales
            out_prncp_inv, # highly correlated with out_prncp
            last_fico_range_low, # highly correlated with last_fico_range_high
            total_rec_prncp # highly correlated with total_pymnt (principal is the amount you borrowed without interest)
            )) %>% 
  drop_na(open_acc) # remove 32 rows as this rows are missing across multiple columns
```

### 2.3 Feature engineering

The target variable in my model is loan_status. The feature has 9 different values. Here they are explained:

- *Current:* Loan is up to date on all outstanding payments. 
- *In Grace Period:* Loan is past due but within the 15-day grace period. 
- *Fully paid:* Loan has been fully repaid, either at the expiration of the 3- or 5-year year term or as a result of a prepayment.
- *Default:* Loan has not been current for an extended period of time.
- *Charged Off:* Loan for which there is no longer a reasonable expectation of further payments. Charge off typically occurs when a loan is 120 days or more past due.  
- *Late (16-30):* Loan has not been current for 16 to 30 days. 
- *Late (31-120):* Loan has not been current for 31 to 120 days.

For this analysis, we are going to keep only observations where loan status contains values "Fully Paid" or "Charred Off". Since our goal is to try to understand and predict if the borrower is going to repay the loan or not. I encoded the variable so it represents only our two possibilities (1 for Fully Paid and 0 for Charged Off). As result, our data-set will be reduced by 547 observations to 41959 in total. 

Further, our data-set has categorical variables containing many multiple labels. Then by using one-hot encoding, we will expand the feature space dramatically. For this reason, the cardinality of some variables was reduced. Closer analysis on these variables was performed initially.

The features related to the past incidences of delinquency, number of inquiries in the past 6 months, number of derogatory public records, late fees received to date, and post charge off gross recovery were converted to the logical variable. As the common value representing the number of incidences was one or two. These values were assigned TRUE and where there wasn't record FALSE was assigned.

The missing values in the Revolving line utilization rate were replaced with median imputation. 
Next, a feature was created that represents the monthly employment expense of the user's repayment expense as a percentage of the monthly salary. 

Variable 'out_prncp' was removed as it doesn't store any values for Fully Paid or Charged Off.

Lastly, after closer analysis, I identified that we can't draw any strong conclusions of whether the 'Charge Off' is affected by the state variable, so we won't be adding 'addr_state' to our model, and the same applies to the issue date.

I concentrated attention at the variables that LendingClub and its investors have about borrower during the initial stage.

```{r}
lending_loans <- lending_loans %>% 
  filter(!loan_status %in% c("Current", "In Grace Period", "Late (31-120 days)", "Late (16-30 days)", "Default")) %>%
  mutate(loan_status = case_when(loan_status == "Fully Paid" ~ T,
                                 loan_status == "Does not meet the credit policy. Status:Fully Paid" ~ T,
                                 loan_status == "Charged Off" ~ F,
                                 loan_status == "Does not meet the credit policy. Status:Charged Off" ~ F
  )) %>% # abstraction: loan status paid = T, charged off = F
  rename("addr_state" = "state_name") %>% 
  mutate(delinq_2yrs = ifelse(delinq_2yrs == 0, F, T), # past-due incidences of delinquency in the borrower's credit file for the past two years
         inq_last_6mths  = ifelse(inq_last_6mths == 0, F, T),
         pub_rec = ifelse(pub_rec == 0, F, T), # derogatory public records
         total_rec_late_fee = ifelse(total_rec_late_fee == 0, F, T), # Late fees received to date
         recoveries = ifelse(recoveries == 0, F, T), # post charge off gross recovery
         collection_recovery_fee = ifelse(collection_recovery_fee == 0, F, T), # post charge off collection fee
         int_rate_pct = str_remove_all(int_rate, "[%]"),
         home_ownership = recode(home_ownership, "NONE" = "OTHER"),
         int_rate_pct = as.numeric(int_rate_pct), # convert interest rate to numeric
         issue_d = str_remove_all(issue_d, "[0-9-]"), # remove year, leave month
         emp_length = case_when(emp_length == "10+ years" ~ "10+ years",
                                emp_length %in% c("9 years", "8 years", "7 years", "6 years") ~ "above 5 years",
                                emp_length %in% c("5 years", "4 years", "3 years", "2 years") ~ "2 - 5 years",
                                emp_length %in% c("1 year", "< 1 year") ~ "1 and under",
                                emp_length == "n/a" ~ "unknown"),
         addr_state = coalesce(addr_state, "unknown"),
         revol_util_pct = str_remove_all(revol_util, "[%]"), # the amount of credit the borrower is using relative to all available revolving credit
         revol_util_pct = as.numeric(revol_util_pct), # convert to numeric
         revol_util_pct = coalesce(revol_util_pct, median(revol_util_pct, na.rm = TRUE)), # replace missing values with median
         pub_rec_bankruptcies = as.character(pub_rec_bankruptcies),
         pub_rec_bankruptcies = case_when(pub_rec_bankruptcies == "0" ~ "no", 
                                          pub_rec_bankruptcies == "1" ~ "yes",
                                          pub_rec_bankruptcies == "2" ~ "yes", 
                                          TRUE ~ "unknown"), # public record bankruptcies
         install_mth_pct = round((installment * 100) / (annual_inc/12), 2), # monthly installment expense %
         fico_range_avg = (fico_range_low + fico_range_high) / 2,
         earliest_cr_line = str_remove_all(earliest_cr_line, "[A-Za-z-]"),
         earliest_cr_line = case_when(earliest_cr_line >= 2000 ~ "00s",
                                      earliest_cr_line >= 1940 ~ "40s-90s",
                                      T ~ "unknown"),
         term_36 = ifelse(term == "36 months", T, F),
         purpose = case_when(purpose %in% c("home_improvement", "house") ~ "house related",
                             purpose %in% c("vacation", "wedding", "car", "major_purchase") ~ "personal",
                             T ~ as.character(purpose)), #  where relevant reduce the amount of variable labels
         purpose = as.factor(purpose)
         ) %>% # if it is not 36, we know it will be 60 months
  mutate_if(is_character, as_factor) %>% 
  select(-c(collection_recovery_fee, int_rate, revol_util, fico_range_low, fico_range_high, addr_state, issue_d, out_prncp, last_fico_range_high, term, recoveries, total_rec_late_fee))
```

#### 2.3.1 Check for aliases in the independent variables
```{r, results = FALSE}
alias(loan_status ~ ., data = lending_loans)
```
All the variables are independent.

#### 2.3.2 Correlation between the features
Now let's check correlation between the features to decide which variables to include in the model. As we can see there is a strong positive correlation between loan amount and three other variables (installment (0.93), total_pymnt (0.88), and total_rec_int (0.73)), therefore, we can exclude them.

```{r, results = FALSE}
# check correlation between numeric features
cor(lending_loans[, sapply(lending_loans, class) == "numeric"])

# remove variables
lending_loans <- lending_loans %>% 
  select(-c(installment, total_pymnt, total_rec_int))
```

## 3. EXPLORATORY ANALYSIS

A principal source of biases the ML models is from the data used to train it. In order to understand our data we will perform Exploratory Data Analysis. The main purpose of exploratory analysis is to help look at data before making any assumptions. It is one of the most important steps before building a model in order to identify obvious errors, as well as better understand patterns within the data, detect outliers or find interesting relations among the variables.


```{r}
loan_status_graph <- lending_loans %>% 
  ggplot(aes (x = loan_status))+
  geom_bar(fill = c("#e41a1c", "#4daf4a"))+
  labs(title = "Distribution of loans by repayment status",
       y = "Count",
       x = "Loan status (Charged off = False, Paid = True)")+
  theme_bw()
```


### 3.1 Loan amount

```{r}
lending_loans %>% 
  ggplot(aes(x = loan_amnt))+
  geom_histogram(fill = "#377eb8", bins = 30)+
  labs(title = "Distribution of Loan Amount",
       x = "Loan Amount",
       y = "Count")+
  theme_bw()
```

```{r}
lending_loans %>% 
  ggplot(aes(x = loan_status, y = loan_amnt))+
  geom_boxplot(fill = c("#e41a1c", "#4daf4a"))+
  coord_flip()+
  labs(title = "Loan Amount by Loan Status",
       x = "Loan Status",
       y = "Loan Amount")+
  theme_bw()
  
```

Charged-off loans tend to have higher loan amounts. 


### 3.2 Interest Rate

```{r}
lending_loans %>% 
  ggplot(aes(x = int_rate_pct))+
  geom_histogram(fill = "#377eb8", bins = 30)+
  labs(title = "Distribution of Interest Rate %",
       x = "Interest Rate %",
       y = "Count")+
  theme_bw()
```

```{r}
lending_loans %>% 
  ggplot(aes(x = loan_status, y = int_rate_pct))+
  geom_boxplot(fill = c("#e41a1c", "#4daf4a"))+
  coord_flip()+
  labs(title = "Interest Rate % by Loan Status",
       x = "Loan Status",
       y = "Interest Rate %")+
  theme_bw()
```

Charged-off loans tend to have much higher interest rates.


### 3.3 Home Ownership

```{r}
lending_loans %>% 
  ggplot(aes(x = home_ownership, fill = loan_status))+
  geom_bar()+
  labs(title = "Loan Status by Home Ownership",
       x = "Home Ownership",
       y = "Count",
       fill = "Loan Status")+
  scale_fill_manual(values = c("#e41a1c", "#4daf4a"))+
  theme_bw()
```

Most of the borrowers are renting or have mortgage. Highest amount of charged-off loans is in the 'rent' category.


### 3.4 Verification Status

```{r}
lending_loans %>% 
  ggplot(aes(x = verification_status, fill = loan_status))+
  geom_bar()+
  labs(title = "Loan Status by Verification Status",
       x = "Verification Status",
       y = "Count",
       fill = "Loan Status")+
  scale_fill_manual(values = c("#e41a1c", "#4daf4a"))+
  theme_bw()
```

Large portion of the borrowers is not verified.


### 3.5 Fico Range

```{r}
lending_loans %>% 
  ggplot(aes(x = fico_range_avg))+
  geom_histogram(fill = "#377eb8", bins = 30)+
  labs(title = "Distribution of Average Fico Range",
       x = "Mean Fico Range",
       y = "Count")+
  theme_bw()
```


```{r}
lending_loans %>% 
  ggplot(aes(x = loan_status, y = fico_range_avg))+
  geom_boxplot(fill = c("#e41a1c", "#4daf4a"))+
  coord_flip()+
  labs(title = "Avg Fico Range by Loan Status",
       x = "Loan Status",
       y = "Meam Fico Range")+
  theme_bw()
```

Charged-off loans tend to have much smaller Fico Range. (*US Fico Range is similar UK's Credit Score)


### 3.6 Purpose

Next we can look at the distribution of loans by the purpose. There is 14 different factors for this variable. For example, 46% of the loans were taken for debt_consolidation and 16% of them were not fully paid. In comparison to loans for 'small businesses', these loans make not even 5% but 28% of them were not fully paid. Therefore, can can assume that there may be some relationship between our target variable and the purpose. 

```{r}
# investigate the amount of charged off loans by purpose category
lending_loans %>% 
 # filter(loan_status == F) %>% 
  group_by(purpose) %>% 
  summarise(count = n()) %>% 
  ggplot(aes(x = reorder(purpose, count), y = count))+
  geom_col(fill = "#377eb8")+
  coord_flip()+
  labs(title = "Loans by Purpose",
       y = "Frequency",
       x = "Purpose")+
  theme_bw()
```

```{r}
# percentage loans by purpose category and Loan status
lending_loans %>% 
  group_by(purpose, loan_status) %>% 
  summarise(purchase_count = n()) %>% 
  mutate(pct = round(purchase_count * 100 / sum(purchase_count))) %>%
  ggplot(aes(x = purpose, y = pct, fill = loan_status))+
  geom_col()+
  coord_flip()+
  labs(title = "% of Loans by Purpose and Loan Status",
       y = "Frequency",
       x = "Purpose",
       fill = "Fully Paid")+
  scale_fill_manual(values = c("#e41a1c", "#4daf4a"))+
  theme_bw()
```


### 3.7 Annual Income

Summary statistics of annual income. We can see that there are few outliers. However, we won't be dealing with them. After closer inspection we could see that our two borrowers with highest annual income took loan for home improvements and it was fully paid so we can well assume that this was the case.

```{r}
lending_loans %>% 
  mutate(annual_inc = annual_inc / 1000) %>% 
  group_by(annual_inc) %>% 
  summarise(frequency = n()) %>% 
  ggplot(aes(x = annual_inc, y = frequency))+
  geom_point(color = "#377eb8")+
  labs(title = "Annual income",
       y = "Frequency",
       x = "Annual income (unit 1000)")+
  theme_bw()
```


```{r, results = FALSE}
lending_loans %>% 
  select(annual_inc, purpose, loan_status) %>% 
  filter(annual_inc > 3000000)
```


### 3.8 Grade

Distribution of loans by grading system is another information that can be beneficial for LendingClub. Loan grading is a classification system that involves assigning a quality score to a loan based on a borrower's credit history, quality of the collateral, and the likelihood of repayment of the principal and interest. I have calculated the percentage of each grading for two loan statuses. We can see that the proportion of loans that are not fully paid increases for poorer risk grades.

```{r}
lending_loans %>% 
  mutate(grade = fct_relevel(grade, "A", "B", "C", "D", "E", "F", "G")) %>% 
  ggplot(aes(x = grade))+
  geom_bar(fill = "#377eb8")+
  labs(title = "Loans by Grade Category",
       y = "Count",
       x = "Grade")+
  theme_bw()
```

```{r}
lending_loans %>% 
  select(grade, loan_status) %>% 
  group_by(grade, loan_status) %>% 
  mutate(grade = fct_relevel(grade, "A", "B", "C", "D", "E", "F", "G")) %>% 
  summarise(grade_count = n()) %>% 
  mutate(pct = round(grade_count * 100 / sum(grade_count))) %>% 
  ggplot(aes(x = grade, y = pct, fill = loan_status))+
  geom_col()+
  labs(title = "Distribution of Loans by Grading System and Loan Status",
       fill = "Fully Paid",
       y = "Percentage",
       x = "Grade")+
  scale_fill_manual(values = c("#e41a1c", "#4daf4a"))+
  theme_bw()
```


## 4. MODEL BUILDING

### 4.1 Feature selection

After we have cleaned and analysed data, we can conclude which features we be included in the model. The model will include following 21 independent variables: loan_amnt, emp_length, home_ownership, annual_inc, verification_status, loan_status, purpose, dti, delinq_2yrs, inq_last_6mths, open_acc, pub_rec, revol_bal, total_acc, pub_rec_bankruptcies, grade, int_rate_pct, revol_util_pct, install_mth_pct, fico_range_avg, term_36.    

### 4.2 Data Spliting

Before building the model we need to split our data into training and test set. We are going to train the classifier on the training data and then we are going to test how good our classifier is on the test data. I have decided to use single test set method where I split data-set into training set (70%) and test set (30%).

```{r, results = FALSE}
# Splitting data set into training and test set
set.seed(42) # making results reproducible

test_indices <- sample(1:nrow(lending_loans), size = as.integer(nrow(lending_loans) * 0.3))

train <- lending_loans %>%
  slice(-test_indices)

test <- lending_loans %>%
  slice(test_indices)

# sanity check
nrow(train) + nrow(test) == nrow(lending_loans)
```

#### 4.2.1  Distribution of training and testing sets

Check the distribution of outcome in the training and testing sets to see that they are roughly comparable.

```{r}
# check the distribution of outcome in the training and testing
train %>%
  tabyl(loan_status)

test %>%
  tabyl(loan_status)
```

### 4.3 Logistic regression - First Model

#### 4.3.1 Fit First Model

After we have carried out data cleaning and data analysis we insert our predictors into the model.

```{r, results = FALSE}
# logistic regression with all predictors
log_reg_model <- glm(loan_status ~ ., data = train, family = binomial(link = "logit"))
summary(log_reg_model)
```


#### 4.3.2 Plotting ROC curve

The receiving operating characteristic (ROC) is a visual measure of classifier performance. Using the proportion of positive data points that are correctly considered as positive and the proportion of negative data points that are mistakenly considered as positive, we generate a graphic that shows the trade off between the rate at which you can correctly predict something with the rate of incorrectly predicting something. Ultimately, we’re concerned about the area under the ROC curve, or AUC. That metric ranges from 0.50 to 1.00, and values above 0.80 indicate that the model does a good job in discriminating between the two categories which comprise our target variable. 

```{r, message=FALSE}
loans_pred <- test %>%
  add_predictions(log_reg_model, type = "response")

roc_pred <- loans_pred %>%
  roc(response = loan_status, predictor = pred)

roc_curve <- ggroc(data = roc_pred, legacy.axes = TRUE) +
  coord_fixed()

roc_curve
```


#### 4.3.3 Area under the ROC Curve

If we calculate the area under the curve (AUC), we can use this as a measure of performance. Better classifiers have curves closer to the top left point, and so have larger AUC values. AUC will range from 0.50 - 1.00. 
```{r, message=FALSE, results=FALSE}
roc_train <- train %>%
  add_predictions(log_reg_model, type = "response") %>%
  roc(response = loan_status, predictor = pred)

auc(roc_train)

roc_test <- test %>%
  add_predictions(log_reg_model, type = "response") %>%
  roc(response = loan_status, predictor = pred)

auc(roc_test)
```

The classification accuracy is relatively low 0.7079 for training set and 0.698 for test set.


#### 4.3.4 Confusion Matrix

```{r, results = FALSE}
# confusion matrix

list(
  log_reg_model= table(test$loan_status,  loans_pred$pred > 0.8) %>% prop.table() %>% round(3)
)
```
true positives (Bottom-right quadrant): these are cases in which we predicted the customer would Fully pay and they did. - 67% accuracy.

true negatives (Top-left quadrant): We predicted loan will be Charged off, and the customer did not fully repay the loan. - 7% accuracy.

false positives (Top-right quadrant): We predicted Charged Off, but they actually Fully Paid. (Also known as a “Type I error.”) - 8%

false negatives (Bottom-left): We predicted loan Fully paid, but it was actually Charged off. (Also known as a “Type II error.”) - 18%

The results show that 67% of the predicted observations are true positive and only 7% are true negative. The model has larger type two error, 18% of predicted observations are false positive in which the model predicts borrower not to fully pay the loan but they actually paid off. And the model has type I error - false negative - 0.8% in which it predicts borrower to fully pay the loan but they didn't.

Our model is fairly poor in predicting who won't pay off the loan.



### 4.4 Logistic regression - Second Model


#### 4.4.1 Automated Model Selection

Using automated model selection with glmulti package to find the best model.
```{r eval=FALSE}
glmulti_search_all_loans <- glmulti(
  loan_status ~ ., 
  data = train,
  level = 1,               # Interactions considered
  method = "g",            # "g" the genetic algorithm (recommended for large sets)
  crit = "bic",            # BIC as criteria
  confsetsize = 10,        # Keep 10 best models
  plotty = F, 
  report = T,              # No plots, but provide interim reports
  fitfunction = "glm",     # glm function
  family = binomial(link = "logit")) # binomial family for logistic regression

summary(glmulti_search_all_loans)
```


#### 4.4.2 Fit Best Model

Creating a second model with the best model features.
```{r, results = FALSE}
# second logistic regression model from glmulti
log_reg_model_2 <- glm(loan_status ~ emp_length + purpose + pub_rec_bankruptcies +  annual_inc + inq_last_6mths + revol_bal + int_rate_pct + revol_util_pct + install_mth_pct + fico_range_avg + term_36, data = train, family = binomial(link = "logit"))
summary(log_reg_model_2)
```


#### 4.4.3 Plotting ROC curve

```{r, message=FALSE}
loans_pred_2 <- test %>%
  add_predictions(log_reg_model_2, type = "response")

roc_pred_2 <- loans_pred_2 %>%
  roc(response = loan_status, predictor = pred)

roc_curve_2 <- ggroc(data = roc_pred_2, legacy.axes = TRUE) +
  coord_fixed()+
  theme_economist()+
  labs(title = "ROC curve\n",
       y = "true positive (sensitivity)\n",
       x = "\nfalse positive (1 - specificity/true negative)")

roc_curve_2
```


#### 4.4.4 Area under the ROC Curve

```{r, message=FALSE, results=FALSE}
roc_train_2 <- train %>%
  add_predictions(log_reg_model_2, type = "response") %>%
  roc(response = loan_status, predictor = pred)

auc(roc_train_2)

roc_test_2 <- test %>%
  add_predictions(log_reg_model_2, type = "response") %>%
  roc(response = loan_status, predictor = pred)

auc(roc_test_2)
```

The classification accuracy is relatively low 0.7067 for training set and 0.6975 for test set.


#### 4.4.5 Confusion Matrix

```{r, results = FALSE}
list(
  log_reg_model= table(test$loan_status,  loans_pred$pred > 0.8) %>% prop.table() %>% round(3),
  log_reg_model_2= table(test$loan_status,  loans_pred_2$pred > 0.8) %>% prop.table() %>% round(3)
)
```

true positives (Bottom-right quadrant): these are cases in which we predicted the customer would Fully pay and they did. - 67% accuracy.

true negatives (Top-left quadrant): We predicted loan will be Charged off, and the customer did not fully repay the loan. - 7% accuracy.

false positives (Top-right quadrant): We predicted Charged Off, but they actually Fully Paid. (Also known as a “Type I error.”) - 8%

false negatives (Bottom-left): We predicted loan Fully paid, but it was actually Charged off. (Also known as a “Type II error.”) - 17%

The results show that 67% of the predicted observations are true positive and only 7% are true negative. The model has larger type two error, 17% of predicted observations are false positive in which the model predicts borrower not to fully pay the loan but they actually paid off. And the model has type I error - false negative 8% - in which it predicts borrower to fully pay the loan but they didn't.

Our model is fairly poor in predicting who won't pay off the loan.


#### 4.4.6 p-values

```{r}
p_value <- tidy(log_reg_model_2)
p_value %>% 
  select(term, p.value) %>% 
  arrange(p.value)
```


#### 4.4.7 Sensitivity and Specificity

Sensitivity is synonymous to precision. However, the specificity is the percentage of defaulters that are correctly identified. In our case, a card company is likely to be more concerned with sensititivy since they want to reduce their risk. 

```{r, results = FALSE}
classifier_data <- tibble(
  threshold = roc_pred_2$thresholds,
  sensitivity = roc_pred_2$sensitivities,
  specificity = roc_pred_2$specificities
)

classifier_data <- classifier_data %>%
  rename(
    tpr = sensitivity,
    tnr = specificity,
  ) %>%
  mutate(
    fpr = 1 - tnr,
    fnr = 1 - tpr
  )

classifier_data
```

```{r}
prob_pos = sum(lending_loans$loan_status == T) / 1000
prob_pos
```

```{r}
prob_neg = sum(lending_loans$loan_status == F) / 1000
prob_neg
```

```{r}
# profits
tpp <- 20
tnp <- 0
fpp <- -100
fnp <- 0

classifier_data <- classifier_data %>%
  mutate(
    exp_profit_per_pot_applicant = 
      prob_pos * (tpr * tpp + fnr * fnp) + 
      prob_neg * (tnr * tnp + fpr * fpp)
  )

classifier_data %>%
  ggplot(aes(x = threshold, y = exp_profit_per_pot_applicant)) +
  geom_line()
```

```{r}
classifier_data %>%
  filter(exp_profit_per_pot_applicant == max(exp_profit_per_pot_applicant))
```

## 5. CONCLUSION
The two most important measures to evaluate models are the accuracy and error. 
The ROC curve will give the real picture about the quality of our mode.
The area under the curve is equal to 0.70. Therefore, it is clear that this model is fairly poor as it is not able to classify correctly loans that are charged off. The main reason for this poor model performance is because the dataset is unbalanced. The model learned from the training set with significantly higher proportion of fully paid compare to charged off loans. Therefore, charged off loan is very rare event in our training data set.

The results show that 67% of the predicted observations are true positive and only 7% are true negative. The model has larger type two error, 17% of predicted observations are false positive in which the model predicts borrower not to fully pay the loan but they actually paid off. And the model has type I error - false negative - 0.8% in which it predicts borrower to fully pay the loan but they didn't.

Our model is fairly poor in predicting who won't pay off the loan.

Looking at the p-values, it can be seen that the most important feature is purpose use for small business, followed by loan term of 36 months, loan inquiry in last 6 months, and interest rate to mention some.

The classification accuracy is a very problematic measure for imbalanced classification which is a common scenario in investment and banking sector and can lead us to make wrong decisions. For this kind of model, the better measure is the ROC-curve which shows true positive rates against false-positive rates.

Model predictive performance can be improved by applying additional methods such as strategy curve, cost-sensitive learning, under sampling, or over sampling.
Other methods can be used for classification for instance random forest, or neural networks.